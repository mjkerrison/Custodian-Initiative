Part of the EA Melbourne Hackathon, March 2023

# Research

EA Forum search terms:
- Custodian
- Revisit

Key orgs / initiatives:
- 80k doesn't have anything much more explicitly retrospective or ruling things 'out', but might be doing research behind the scenes that doesn't get published as it is indeed a 'no action' result
- Rethink Priorities obviously has a backlog of research, but nothing quite like this proposal
- Open Philanthropy
	- Some, but incidental (e.g. https://www.openphilanthropy.org/research/tobacco-control/)
	- There's some things that look backwards (e.g. the History of Philanthropy work) but nothing that quite seems the same
- EA Forum
	- By its nature more ad hoc
	- Red teaming / Change Our Mind contests also don't seem to foster this systematically.
- ❓ Non-EA - e.g. Gates or Bloomberg Foundations? Could these be relied on?
	- If so, theres still probably room for more of an aggregator?


# UVP

- The Custodian Initiative addresses a particular failure mode that I haven't seen addressed elswhere. It's one thing to make a moral mistake - and people are conducting plenty of research on this - but another to get something morally right *at the time*, and fail to notice a discovery that changes that calculus.
- It takes its name from the 4X strategy game *Stellaris*, which implemented a Custodian Initiative to steward old content - not just fixing bugs, but actively supporting and enriching existing content, while the rest of the team pushes ahead with new content, expansions and so on.
- This connects with the concept of "looking for your keys under the streetlight".
- Another analogy is with investing / financial advice: confirmation that you're on the right track is also important (what are the trades one *didn't* make?)
- It's probably really a sub-field of global priorities research - but looking backwards, rather than forwards.
- Another link is to the replication crisis

# Similar ideas

- Priorities research
- Various red team initiatives
- Changes in cause areas: 
	- EA Survey
		- 2020 survey results @ https://forum.effectivealtruism.org/posts/83tEL2sHDTiWR6nwo/ea-survey-2020-cause-prioritization
		- David Moss estimated 2022 results circa late March 2023 (comment on the announcement post dated 6 March)
- Changes in interventions:
	- https://forum.effectivealtruism.org/posts/RcSf7eGKF9E8XNAra/a-major-update-in-our-assessment-of-water-quality-3
- Similar attempts:
	- https://forum.effectivealtruism.org/posts/BFvtrhaea85CDYhBQ/ea-has-gotten-it-very-wrong-on-climate-change-a-canadian
- Individual people changing their mind on particular things - but maybe more "under the streetlight":
	- https://forum.effectivealtruism.org/posts/wc2LwxagsgwmoXnrr/revisiting-why-global-poverty

# ITN

## Importance

- Might also play into the recent discussion of epistemics; this proposal effectively calls for systematic or even institutional red teaming of priorities (though in the 'backward' direction).

❓ What's the impact of a missed update?

## Neglectedness

- Particular individuals are well suited to updating the community on issues in particular fields. For instance, I would expect that new discoveries in AI safety or moral uncertainty that impact their ITN assessment will be disseminated pretty quickly, as there are people actively looking ("under the streetlight").
- Similarly, funding bodies have incentives / do / should keep an eye on the effectiveness (i.e. ITN) of a particular cause area or specific intervention.[^1]
- However, these are cases where people have 'dropped their keys', and are looking for them 'under the streetlight'. There may be particular issues or fields that no one is keeping an eye on, or not enough people are keeping an eye on, or no one with enough social capital is keeping an eye on.
- I think a good candidate for this is climate change. I found Will MacAskill's analysis in *What We Owe the Future* compelling: it's an area that is important and seems to be tractable in some ways and less tractable in others, but not really neglected, and not as neglected as other cause areas. Whenever I discuss this with friends or colleagues who are less inclined to this way of thinking, the stance I generally end up taking is that 'yes it's important, but the next dollar is probably better spent elsewhere; *I'm not explicitly advocating for decreasing funding*'.
- Now, it may very well be that actually the current amount of spending does not represent an optimal marginal rate of substitution between issues - maybe governments *ought* to spend less on climate change, and more on something else.
- However, my claim is about the minimum, and about my placatory corollary. I don't think EA writ large should spend much time or effort on climate change, *given how things stand today*. I could well imagine that this could change on any of the ITN dimensions, such that it does become sensible for EA to engage. It could be that we discover some fact that makes it look more important (e.g. some cascade-flavoured theory is shown to be much more likely); much more neglected (e.g. coordination actively worsens and governments wind back effort); or much more tractable, in some way that EA is particularly well-positioned to leverage.
- The risk I propose is that because EA generally prioritises, and suggests that interested individuals prioritise, other areas. This means there are areas where we are not cultivating expertise, and are therefore reliant on other sources for updates. 
- For some issues, this may be sufficient - meaningful shifts in climate change, e.g. in technological solutions, seem likely to be heavily publicised.
- The key questions I see are:
	- Which areas present this risk?
	- What is the risk actually presented?
		- What is the right base case, and what is its base rate?



## Tractability

- 'Pull' methods
	- ❓ Build this into GPR: a "good" paper should define minimal conditions that call for revisiting
		- Taking this to zany town: smart contracts might be useful?
- 'Push' methods
	- ❓ Fund custodians (e.g. some number of GPI researchers) to rotate through key areas on a regular basis - could be a lower barrier to entry, as it likely looks like literature reviews, rather than cutting-edge research

# Candidate areas

- Climate change
- Nanotechnology? That one's fallen out of favour
- More classical areas like homelessness and criminal justice - these have come up in my EA social circles recently
- 

# Footnotes

[^1]: https://forum.effectivealtruism.org/posts/RD9ztxR4y6jYaPbT7/room-for-more-funding-why-doesn-t-the-gates-foundation-just - details of the Gates Foundation and how they move their funding around